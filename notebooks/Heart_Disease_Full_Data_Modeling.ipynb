{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 1: Загрузка всех данных и объединение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleveland загружен: 303 записей.\n",
      "Hungarian загружен: 294 записей.\n",
      "Switzerland загружен: 123 записей.\n",
      "Va загружен: 200 записей.\n",
      "Пропущенных значений после заполнения: 0\n",
      "Итоговый размер датасета: (920, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       920 non-null    float64\n",
      " 1   sex       920 non-null    float64\n",
      " 2   cp        920 non-null    float64\n",
      " 3   trestbps  920 non-null    float64\n",
      " 4   chol      920 non-null    float64\n",
      " 5   fbs       920 non-null    float64\n",
      " 6   restecg   920 non-null    float64\n",
      " 7   thalach   920 non-null    float64\n",
      " 8   exang     920 non-null    float64\n",
      " 9   oldpeak   920 non-null    float64\n",
      " 10  slope     920 non-null    float64\n",
      " 11  ca        920 non-null    float64\n",
      " 12  thal      920 non-null    float64\n",
      " 13  target    920 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 100.8 KB\n",
      "None\n",
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    3.0  0.0   6.0       0  \n",
      "1    2.0  3.0   3.0       1  \n",
      "2    2.0  2.0   7.0       1  \n",
      "3    3.0  0.0   3.0       0  \n",
      "4    1.0  0.0   3.0       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Общий список колонок\n",
    "\n",
    "columns = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "    'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
    "    'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Ссылки на датасеты\n",
    "urls = {\n",
    "    'cleveland': 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data',\n",
    "    'hungarian': 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data',\n",
    "    'switzerland': 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data',\n",
    "    'va': 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.va.data'\n",
    "}\n",
    "\n",
    "# загрузка и объединение данных\n",
    "dfs = []\n",
    "for clinic, url in urls.items():\n",
    "    temp_df = pd.read_csv(url, names=columns)\n",
    "    temp_df.replace('?', pd.NA, inplace=True)\n",
    "    print(f'{clinic.capitalize()} загружен: {temp_df.shape[0]} записей.')\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "# объединяем в один датафрейм\n",
    "df_full = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Заполнение пропусков медианой\n",
    "# Корректное заполнение пропусков медианой без chained assignment\n",
    "for col in df_full.columns:\n",
    "    df_full[col] = pd.to_numeric(df_full[col], errors='coerce')\n",
    "    median = df_full[col].median()\n",
    "    df_full[col] = df_full[col].fillna(median)\n",
    "\n",
    "# Проверим ещё раз отсутствие пропусков\n",
    "print('Пропущенных значений после заполнения:', df_full.isnull().sum().sum())\n",
    "\n",
    "\n",
    "# Бинаризация целевой переменной\n",
    "df_full['target'] = df_full['target'].apply(lambda x: 1 if int(x) > 0 else 0)\n",
    "\n",
    "# Проверка итогового датасета\n",
    "print('Итоговый размер датасета:', df_full.shape)\n",
    "print(df_full.info())\n",
    "print(df_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (736, 22) (736,)\n",
      "Test shape: (184, 22) (184,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# One-Hot Encoding категориальных признаков\n",
    "df_encoded = pd.get_dummies(df_full, columns=['cp', 'thal', 'restecg', 'slope'])\n",
    "\n",
    "# Делим на признаки (X) и целевую переменную (y)\n",
    "X = df_encoded.drop('target', axis=1)\n",
    "y = df_encoded['target']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Масштабирование числовых признаков\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Числовые признаки для масштабирования\n",
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
    "\n",
    "# Применяем масштабирование\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Проверка размеров\n",
    "print('Train shape:', X_train.shape, y_train.shape)\n",
    "print('Test shape:', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Лучшая точность (CV): 0.8178985107556537\n",
      "\n",
      "Точность на тестовых данных: 0.8260869565217391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.79        82\n",
      "           1       0.82      0.88      0.85       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.83      0.82      0.82       184\n",
      "weighted avg       0.83      0.83      0.82       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# параметры для поиска лучших гиперпараметров\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), \n",
    "                    param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# обучение\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры и точность модели\n",
    "print(\"Лучшие параметры:\", grid.best_params_)\n",
    "print(\"Лучшая точность (CV):\", grid.best_score_)\n",
    "\n",
    "# Тестирование модели на тестовой выборке\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Оценка результатов\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"\\nТочность на тестовых данных:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Сохраняем модель в файл\n",
    "joblib.dump(best_model, 'heart_disease_model.pkl')\n",
    "\n",
    "# Сохраняем scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
